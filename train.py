import torch
import torch.nn as nn
import torch.nn.functional as F
from dataloader import get_dataloaders
from U_net import UNet

def dice_score(pred, target, num_classes, smooth=1e-5):
    """
    CalculeazÄƒ Dice Score pentru evaluarea segmentÄƒrii.
    
    Dice Score mÄƒsoarÄƒ overlap-ul dintre predicÈ›ie È™i ground truth.
    Formula: Dice = 2 * |A âˆ© B| / (|A| + |B|)
    
    Args:
        pred (Tensor): predicÈ›iile modelului cu shape (batch_size, H, W)
        target (Tensor): ground truth cu shape (batch_size, H, W)
        num_classes (int): numÄƒrul de clase
        smooth (float): factor de regularizare pentru evitarea diviziunii cu 0
    
    Returns:
        tuple: (dice_per_class, mean_dice)
            - dice_per_class: lista cu Dice Score pentru fiecare clasÄƒ
            - mean_dice: media Dice Score-urilor pentru toate clasele
    """
    # ConverteÈ™te predicÈ›iile È™i target-urile la format one-hot
    pred_one_hot = F.one_hot(pred, num_classes=num_classes).permute(0,3,1,2).float()
    target_one_hot = F.one_hot(target, num_classes=num_classes).permute(0,3,1,2).float()
    
    dice = []
    # CalculeazÄƒ Dice Score pentru fiecare clasÄƒ
    for i in range(num_classes):
        p = pred_one_hot[:, i]  # PredicÈ›iile pentru clasa i
        t = target_one_hot[:, i]  # Ground truth pentru clasa i
        
        # CalculeazÄƒ intersecÈ›ia È™i uniunea
        intersection = (p * t).sum(dim=(1,2))
        union = p.sum(dim=(1,2)) + t.sum(dim=(1,2))
        
        # CalculeazÄƒ Dice Score cu factor de regularizare
        dice_class = ((2 * intersection + smooth) / (union + smooth)).mean().item()
        dice.append(dice_class)
    
    # ReturneazÄƒ Dice Score-urile per clasÄƒ È™i media
    return dice, sum(dice)/len(dice)

def train_epoch(model, device, dataloader, optimizer, criterion):
    """
    AntreneazÄƒ modelul pentru o epocÄƒ.
    
    Args:
        model: modelul U-Net
        device: device-ul de calcul ('cpu' sau 'cuda')
        dataloader: DataLoader pentru datele de antrenare
        optimizer: optimizatorul (ex: Adam)
        criterion: funcÈ›ia de loss (ex: CrossEntropyLoss)
    
    Returns:
        float: loss-ul mediu pentru epoca curentÄƒ
    """
    model.train()  # SeteazÄƒ modelul Ã®n modul de antrenare
    running_loss = 0.0
    
    for images, labels in dataloader:
        # TransferÄƒ datele pe device-ul de calcul
        images = images.to(device)
        labels = labels.to(device)
        
        # ReseteazÄƒ gradientii
        optimizer.zero_grad()
        
        # Forward pass
        outputs = model(images)
        
        # CalculeazÄƒ loss-ul
        loss = criterion(outputs, labels)
        
        # Backward pass
        loss.backward()
        
        # ActualizeazÄƒ parametrii
        optimizer.step()
        
        # AcumuleazÄƒ loss-ul
        running_loss += loss.item() * images.size(0)
    
    # ReturneazÄƒ loss-ul mediu pe epocÄƒ
    return running_loss / len(dataloader.dataset)

def validate_epoch(model, device, dataloader, num_classes):
    """
    EvalueazÄƒ modelul pe setul de validare.
    
    Args:
        model: modelul U-Net
        device: device-ul de calcul
        dataloader: DataLoader pentru datele de validare
        num_classes: numÄƒrul de clase pentru segmentare
    
    Returns:
        tuple: (dice_per_class, mean_dice)
            - dice_per_class: Dice Score pentru fiecare clasÄƒ
            - mean_dice: media Dice Score-urilor
    """
    model.eval()  # SeteazÄƒ modelul Ã®n modul de evaluare
    dice_per_class = [0.0] * num_classes
    mean_dice = 0.0
    count = 0
    
    with torch.no_grad():  # DezactiveazÄƒ calculul gradientilor pentru eficienÈ›Äƒ
        for images, labels in dataloader:
            # TransferÄƒ datele pe device
            images = images.to(device)
            labels = labels.to(device)
            
            # Forward pass
            outputs = model(images)
            
            # ConverteÈ™te logits la predicÈ›ii de clase
            preds = torch.argmax(outputs, dim=1)
            
            # CalculeazÄƒ Dice Score
            dice, mean = dice_score(preds, labels, num_classes)
            
            # AcumuleazÄƒ rezultatele
            dice_per_class = [d + dc for d, dc in zip(dice, dice_per_class)]
            mean_dice += mean
            count += 1
    
    # CalculeazÄƒ media pe toate batch-urile
    dice_per_class = [d / count for d in dice_per_class]
    mean_dice = mean_dice / count
    
    return dice_per_class, mean_dice

def train_model(json_path, epochs=10, batch_size=4, lr=1e-3, device='cuda' if torch.cuda.is_available() else 'cpu'):
    """
    FuncÈ›ia principalÄƒ pentru antrenarea modelului U-Net.
    
    Args:
        json_path (str): calea cÄƒtre fiÈ™ierul JSON cu datele
        epochs (int): numÄƒrul de epoci de antrenare
        batch_size (int): dimensiunea batch-ului
        lr (float): learning rate pentru optimizer
        device (str): device-ul de calcul ('cpu' sau 'cuda')
    
    Returns:
        model: modelul antrenat
    """
    print(f"ğŸš€ Ãncepe antrenarea pe device: {device}")
    print(f"âš™ï¸  Parametri: epochs={epochs}, batch_size={batch_size}, lr={lr}")
    
    # CreeazÄƒ DataLoader-ele pentru antrenare È™i validare
    train_loader, val_loader = get_dataloaders(json_path, batch_size=batch_size, augment=True)
    print(f"ğŸ“Š Dataset Ã®ncÄƒrcat: {len(train_loader.dataset)} samples pentru antrenare, "
          f"{len(val_loader.dataset)} pentru validare")
    
    # CreeazÄƒ modelul U-Net (3 canale input, 3 clase output)
    model = UNet(n_channels=3, n_classes=3).to(device)
    print(f"ğŸ§  Model creat cu {sum(p.numel() for p in model.parameters())} parametri")
    
    # ConfigureazÄƒ optimizatorul È™i funcÈ›ia de loss
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    criterion = nn.CrossEntropyLoss()
    
    print("ğŸ‹ï¸  Ãncepe antrenarea...")
    print("-" * 80)
    
    # Bucla principalÄƒ de antrenare
    for epoch in range(epochs):
        # AntreneazÄƒ o epocÄƒ
        train_loss = train_epoch(model, device, train_loader, optimizer, criterion)
        
        # EvalueazÄƒ pe setul de validare
        dice_per_class, mean_dice = validate_epoch(model, device, val_loader, num_classes=3)
        
        # AfiÈ™eazÄƒ rezultatele
        class_names = ["Fundal", "Prostata", "Zona perifericÄƒ"]
        dice_str = " | ".join([f"{name}: {dice:.4f}" for name, dice in zip(class_names, dice_per_class)])
        
        print(f"Epoca {epoch+1:2d}/{epochs} | "
              f"Loss: {train_loss:.4f} | "
              f"Mean Dice: {mean_dice:.4f}")
        print(f"            Dice per clasÄƒ: {dice_str}")
        print("-" * 80)
    
    print("âœ… Antrenarea completÄƒ!")
    return model

if __name__ == '__main__':
    # Exemplu de utilizare
    print("ğŸ”¬ Sistem de Segmentare a Prostatei cu U-Net")
    print("=" * 50)
    
    # VerificÄƒ dacÄƒ existÄƒ un fiÈ™ier JSON de test
    import os
    if os.path.exists("train.json"):
        print("ğŸ“ FiÈ™ierul train.json gÄƒsit. Ãncepe antrenarea...")
        train_model("train.json", epochs=10, batch_size=4)
    else:
        print("âš ï¸  FiÈ™ierul train.json nu a fost gÄƒsit!")
        print("ğŸ“ CreeazÄƒ un fiÈ™ier train.json cu urmÄƒtoarea structurÄƒ:")
        print("""
{
  "Pacient": [
    {
      "data": "path/to/image1.png",
      "label": "path/to/mask1.png"
    },
    {
      "data": "path/to/image2.png", 
      "label": "path/to/mask2.png"
    }
  ]
}
        """)
        print("\nğŸ’¡ Sau ruleazÄƒ demo.py pentru o demonstraÈ›ie a sistemului!")
        print("   python demo.py")
